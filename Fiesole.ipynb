{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fiesole\n",
    "\n",
    "This project aims to demonstrate the feasibility of Vertical-Federated-Learning CNN architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "MNIST_CLASSES = 10\n",
    "LEARNING_RATE = 0.001\n",
    "ALL_HANDS_ON_DECK = 5\n",
    "\n",
    "\n",
    "class QuadrantTransform:\n",
    "    def __init__(self, quadrant):\n",
    "        assert quadrant in [\n",
    "            \"tl\",\n",
    "            \"tr\",\n",
    "            \"bl\",\n",
    "            \"br\",\n",
    "        ], \"Invalid quadrant. Choose from 'tl', 'tr', 'bl', 'br'\"\n",
    "        self.quadrant = quadrant\n",
    "\n",
    "    def __call__(self, img):\n",
    "        # Convert PIL image to tensor\n",
    "        tensor = transforms.ToTensor()(img)\n",
    "\n",
    "        # Create a blank (transparent) tensor of the same shape\n",
    "        blank = torch.zeros_like(tensor)\n",
    "\n",
    "        if self.quadrant == \"tl\":\n",
    "            blank[:, :14, :14] = tensor[:, :14, :14]\n",
    "        elif self.quadrant == \"tr\":\n",
    "            blank[:, :14, 14:] = tensor[:, :14, 14:]\n",
    "        elif self.quadrant == \"bl\":\n",
    "            blank[:, 14:, :14] = tensor[:, 14:, :14]\n",
    "        elif self.quadrant == \"br\":\n",
    "            blank[:, 14:, 14:] = tensor[:, 14:, 14:]\n",
    "\n",
    "        # Normalize after applying the quadrant transformation\n",
    "        blank = (blank - 0.5) / 0.5\n",
    "\n",
    "        return blank\n",
    "\n",
    "\n",
    "transform_tl = transforms.Compose([QuadrantTransform(\"tl\")])\n",
    "transform_tr = transforms.Compose([QuadrantTransform(\"tr\")])\n",
    "transform_bl = transforms.Compose([QuadrantTransform(\"bl\")])\n",
    "transform_br = transforms.Compose([QuadrantTransform(\"br\")])\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "\n",
    "trainset_tl = torchvision.datasets.MNIST(\n",
    "    root=\"./control\", train=True, download=True, transform=transform_tl\n",
    ")\n",
    "trainset_tr = torchvision.datasets.MNIST(\n",
    "    root=\"./control\", train=True, download=True, transform=transform_tr\n",
    ")\n",
    "trainset_bl = torchvision.datasets.MNIST(\n",
    "    root=\"./control\", train=True, download=True, transform=transform_bl\n",
    ")\n",
    "trainset_br = torchvision.datasets.MNIST(\n",
    "    root=\"./control\", train=True, download=True, transform=transform_br\n",
    ")\n",
    "\n",
    "trainloader_tl = torch.utils.data.DataLoader(trainset_tl, batch_size=4)\n",
    "trainloader_tr = torch.utils.data.DataLoader(trainset_tr, batch_size=4)\n",
    "trainloader_bl = torch.utils.data.DataLoader(trainset_bl, batch_size=4)\n",
    "trainloader_br = torch.utils.data.DataLoader(trainset_br, batch_size=4)\n",
    "\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=\"./control\", train=False, download=True, transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc_relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc_relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def test_model(debug_string, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(debug_string, correct / total)\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "# Training loop\n",
    "def train_model(model, trainloader, optimizer):\n",
    "    num_epochs = 1\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(trainloader):\n",
    "            if torch.cuda.is_available():\n",
    "                model = model.cuda()\n",
    "                images = images.cuda()\n",
    "                labels = labels.cuda()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def average_weights(*models):\n",
    "    \"\"\"Averages the weights of the given models.\"\"\"\n",
    "    avg_dict = {}\n",
    "\n",
    "    # Get the state dictionary of the first model to initialize the avg_dict\n",
    "    for key in models[0].state_dict().keys():\n",
    "        avg_dict[key] = sum([model.state_dict()[key] for model in models]) / len(models)\n",
    "\n",
    "    return avg_dict\n",
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "tl_history = []\n",
    "tr_history = []\n",
    "bl_history = []\n",
    "br_history = []\n",
    "avg_history = []\n",
    "\n",
    "\n",
    "def federated_learning(original_model):\n",
    "    model_tl = copy.deepcopy(original_model)\n",
    "    optimizer_tl = optim.Adam(model_tl.parameters(), lr=LEARNING_RATE)\n",
    "    model_tr = copy.deepcopy(original_model)\n",
    "    optimizer_tr = optim.Adam(model_tr.parameters(), lr=LEARNING_RATE)\n",
    "    model_bl = copy.deepcopy(original_model)\n",
    "    optimizer_bl = optim.Adam(model_bl.parameters(), lr=LEARNING_RATE)\n",
    "    model_br = copy.deepcopy(original_model)\n",
    "    optimizer_br = optim.Adam(model_br.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "    train_model(model_tl, trainloader_tl, optimizer_tl)\n",
    "    tl_history.append(test_model(\"TL\", model_tl))\n",
    "\n",
    "    train_model(model_tr, trainloader_tr, optimizer_tr)\n",
    "    tr_history.append(test_model(\"TR\", model_tr))\n",
    "\n",
    "    train_model(model_bl, trainloader_bl, optimizer_bl)\n",
    "    bl_history.append(test_model(\"BL\", model_bl))\n",
    "\n",
    "    train_model(model_br, trainloader_br, optimizer_br)\n",
    "    br_history.append(test_model(\"BR\", model_br))\n",
    "\n",
    "    avg_state_dict = average_weights(model_tl, model_tr, model_bl, model_br)\n",
    "\n",
    "    new_model = CNN()\n",
    "    new_model.load_state_dict(avg_state_dict)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        new_model = new_model.cuda()\n",
    "\n",
    "    avg_history.append(test_model(\"avg\", new_model))\n",
    "    return new_model\n",
    "\n",
    "\n",
    "for i in range(ALL_HANDS_ON_DECK):\n",
    "    print(f\"Iteration {i+1}\")\n",
    "    model = federated_learning(model)\n",
    "\n",
    "\n",
    "# Plot the results\n",
    "plt.plot(tl_history, label=\"TL\")\n",
    "plt.plot(tr_history, label=\"TR\")\n",
    "plt.plot(bl_history, label=\"BL\")\n",
    "plt.plot(br_history, label=\"BR\")\n",
    "plt.plot(avg_history, label=\"avg\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Federations\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Project Fiesole\")\n",
    "import datetime\n",
    "\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "plt.savefig(\"fiesole-\" + current_time + \".png\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "torch.save(model.state_dict(), \"fiesole.ckpt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
